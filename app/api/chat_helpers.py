import json
import re
import secrets
from typing import Any, Dict, List, Optional

from app.config import Config
from app.schemas import ChatRequest


def _extract_rich_content(context_text: str) -> Dict[str, Any]:
    """Extract URLs, images, and map links from RAG context for rich display."""
    links: List[Dict[str, str]] = []
    images: List[Dict[str, str]] = []
    seen_urls: set = set()

    if not context_text:
        return {"links": links, "images": images}

    # --- Staff profile URLs (structured format: [staff] name: X | ... | profile_url: URL) ---
    staff_blocks = re.finditer(
        r"\[staff\]\s*name:\s*([^|]+?)(?:\s*\|)", context_text, re.IGNORECASE,
    )
    for block_match in staff_blocks:
        staff_name = block_match.group(1).strip()
        # Find profile_url in the same staff block (until next [staff] or section break)
        block_start = block_match.start()
        next_block = re.search(r"\[staff\]|\[conf:", context_text[block_start + 10:])
        block_end = (block_start + 10 + next_block.start()) if next_block else len(context_text)
        block_text = context_text[block_start:block_end]
        url_match = re.search(r"profile_url:\s*(https?://[^\s|,\]]+)", block_text)
        if url_match:
            url = url_match.group(1).strip().rstrip("'\"}")
            if url not in seen_urls:
                seen_urls.add(url)
                label = f"View {staff_name}'s Profile" if staff_name else "View Staff Profile"
                links.append({"url": url, "type": "staff_profile", "label": label})

    # Fallback: legacy dict format {'profile_url': 'URL', 'name': 'X'}
    legacy_staff = re.finditer(
        r"['\"]?profile_url['\"]?\s*:\s*['\"]?(https?://[^\s'\"}\|,]+)", context_text,
    )
    for match in legacy_staff:
        url = match.group(1).strip().rstrip("'\"}")
        if url not in seen_urls:
            seen_urls.add(url)
            # Try to extract name from nearby context
            nearby = context_text[max(0, match.start() - 200):match.start()]
            name_match = re.search(r"['\"]?name['\"]?\s*:\s*['\"]?([^'\"}\|,]+)", nearby)
            name = name_match.group(1).strip() if name_match else ""
            label = f"View {name}'s Profile" if name else "View Staff Profile"
            links.append({"url": url, "type": "staff_profile", "label": label})

    # --- Building images (CampusBlocks) ---
    image_matches = re.finditer(
        r"building_image:\s*(https?://[^\s\|,\]]+)", context_text, re.IGNORECASE,
    )
    for match in image_matches:
        url = match.group(1).strip().rstrip("'\"| ")
        if url and url not in seen_urls:
            seen_urls.add(url)
            # Extract block name from preceding context
            preceding = context_text[max(0, match.start() - 300):match.start()]
            name_match = re.search(r"name:\s*([^|]+)", preceding)
            block_name = name_match.group(1).strip() if name_match else ""
            label = block_name if block_name else "Building Image"
            images.append({"url": url, "type": "building_image", "label": label})

    # --- Map links (CampusBlocks) ---
    map_matches = re.finditer(
        r"(?:^|\|)\s*map:\s*(https?://[^\s\|,\]]+)", context_text, re.IGNORECASE,
    )
    for match in map_matches:
        url = match.group(1).strip().rstrip("'\"| ")
        if url and url not in seen_urls:
            seen_urls.add(url)
            links.append({"url": url, "type": "map", "label": "View on Map"})

    # --- Programme URLs ---
    url_matches = re.finditer(r"Url:\s*(https?://[^\s\|,\]]+)", context_text)
    for match in url_matches:
        url = match.group(1).strip().rstrip("'\"| ")
        if url and url not in seen_urls:
            seen_urls.add(url)
            links.append({"url": url, "type": "programme_info", "label": "More Information"})

    return {"links": links, "images": images}

def _user_student_number(user: Optional[dict]) -> str:
    return str((user or {}).get("sub") or (user or {}).get("student_number") or "").strip()


def _user_display_name(user: Optional[dict]) -> str:
    name = str((user or {}).get("name") or "").strip()
    return name or "Guest"


def _resolve_session(user: Optional[dict], request_body: ChatRequest):
    student_number = _user_student_number(user)
    if student_number:
        return f"user:{student_number}", student_number, False

    cid = request_body.conversation_id
    if cid:
        return f"guest:{cid}", cid, False

    new_id = secrets.token_hex(8)
    return f"guest:{new_id}", new_id, True


def _contains_token(text: str, keyword: str) -> bool:
    t = (text or "").lower()
    kw = (keyword or "").strip().lower()
    if not t or not kw:
        return False
    if " " in kw:
        return kw in t
    return re.search(rf"(?<![a-z0-9]){re.escape(kw)}(?![a-z0-9])", t) is not None


def _is_grade_query(message: str, search_term: Optional[str]) -> bool:
    q = (message or "").lower()
    st = (search_term or "").lower()
    keywords = [
        "grade",
        "result",
        "exam",
        "score",
        "gpa",
        "cgpa",
        "ì„±ì ",
        "ì ìˆ˜",
        "í•™ì ",
        "í‰ì ",
    ]
    return any(k in q for k in keywords) or st in {
        "grades",
        "gpa",
        "cgpa",
        "result",
        "ì„±ì ",
        "í•™ì ",
    }


def _is_personal_query(message: str, search_term: Optional[str]) -> bool:
    q = (message or "").lower()
    st = (search_term or "").lower()
    personal_patterns = [
        "my grade",
        "my gpa",
        "my result",
        "my profile",
        "my information",
        "my info",
        "my id",
        "my nationality",
        "my advisor",
        "my adviser",
        "my major",
        "my programme",
        "my program",
        "where am i from",
        "what is my nationality",
        "what's my nationality",
        "who is my advisor",
        "who is my adviser",
        "what is my major",
        "what's my major",
        "who am i",
        "ë‚´ ì •ë³´",
        "ë‚´ í”„ë¡œí•„",
        "ë‚´ ì„±ì ",
        "ë‚´ í•™ì ",
        "ë‚´ ì ìˆ˜",
        "ë‚´ gpa",
        "ë‚´ êµ­ì ",
        "ë‚´ ì „ê³µ",
        "ë‚´ í•™ë²ˆ",
        "ë‚˜ëŠ” ëˆ„êµ¬",
        "ë‚´ ì§€ë„êµìˆ˜",
    ]
    if st in {
        "self",
        "my",
        "profile",
        "nationality",
        "advisor",
        "adviser",
        "major",
        "programme",
        "program",
        "ë‚´ ì •ë³´",
        "ë‚´ ì„±ì ",
        "êµ­ì ",
        "ì „ê³µ",
        "í•™ë²ˆ",
    }:
        return True
    return any(p in q for p in personal_patterns)


def _normalize_suggestions(items: Any, limit: int = 3) -> List[str]:
    if not isinstance(items, list):
        return []
    out: List[str] = []
    seen = set()
    for item in items:
        text = re.sub(r"\s+", " ", str(item or "").strip())
        if not text:
            continue
        key = text.lower()
        if key in seen:
            continue
        seen.add(key)
        out.append(text)
        if len(out) >= max(1, int(limit)):
            break
    return out


def _has_ucsi_context(message: str) -> bool:
    q = (message or "").strip().lower()
    if not q:
        return False
    hints = [
        "ucsi",
        "university",
        "campus",
        "faculty",
        "school",
        "student",
        "staff",
        "lecturer",
        "professor",
        "dean",
        "advisor",
        "adviser",
        "programme",
        "program",
        "hostel",
        "tuition",
        "fee",
        "block",
        "building",
        "í•™êµ",
        "ëŒ€í•™",
        "ìº í¼ìŠ¤",
        "ê¸°ìˆ™ì‚¬",
        "ë“±ë¡ê¸ˆ",
        "í•™ê³¼",
        "êµìˆ˜",
        "ì§ì›",
    ]
    return any(_contains_token(q, token) for token in hints)


def _extract_person_candidate(message: str) -> Optional[str]:
    text = str(message or "").strip()
    if not text:
        return None

    patterns = [
        r"^\s*who is\s+(?P<name>.+?)\s*\??\s*$",
        r"^\s*who's\s+(?P<name>.+?)\s*\??\s*$",
        r"^\s*do you know\s+(?P<name>.+?)\s*\??\s*$",
        r"^\s*tell me about\s+(?P<name>.+?)\s*\??\s*$",
        r"^\s*tell me more about\s+(?P<name>.+?)\s*\??\s*$",
        r"^\s*what do you know about\s+(?P<name>.+?)\s*\??\s*$",
        r"^\s*(?P<name>[A-Za-z0-9ê°€-í£.\-\'\s]+?)\s*(?:ì— ëŒ€í•´|ì—ëŒ€í•´|ì— ëŒ€í•´ì„œ|ì—ëŒ€í•´ì„œ|ê´€ë ¨í•´ì„œ|ì— ê´€í•œ)\s*(?:ì •ë³´ë¥¼\s*)?(?:ì•Œë ¤ì¤˜|ì•Œë ¤ì¤„ë˜|ì•Œë ¤ì£¼ì„¸ìš”|ë§í•´ì¤˜|ë§í•´ì¤„ë˜|ì„¤ëª…í•´ì¤˜|ì†Œê°œí•´ì¤˜)?\s*\??\s*$",
        r"^\s*(?P<name>[A-Za-z0-9ê°€-í£.\-\'\s]+?)\s*(?:ëˆ„êµ¬ì•¼|ëˆ„êµ¬ì˜ˆìš”|ëˆ„êµ°ê°€ìš”)\s*\??\s*$",
        r"^\s*(?P<name>[A-Za-z0-9ê°€-í£.\-\'\s]+?)\s*(?:ì•Œì•„|ì•Œê³  ìˆì–´|ì•Œê³  ìˆë‹ˆ)\s*\??\s*$",
    ]

    fuzzy_patterns = [
        r"(?:about|regarding|on)\s+(?P<name>[A-Za-z][A-Za-z0-9 .'\-]{1,60})",
        r"(?P<name>[A-Za-z0-9ê°€-í£.\-\'\s]{2,60})\s*(?:ì´ë¼ëŠ”|ë¼ëŠ”)\s*(?:ì‚¬ëŒ|ì¸ë¬¼)?\s*(?:ì— ëŒ€í•´|ì— ëŒ€í•´ì„œ|ê´€ë ¨í•´ì„œ|ì— ê´€í•œ)",
    ]

    candidate = None
    for pattern in patterns:
        m = re.match(pattern, text, flags=re.IGNORECASE)
        if m:
            candidate = m.group("name")
            break

    if not candidate:
        for pattern in fuzzy_patterns:
            m = re.search(pattern, text, flags=re.IGNORECASE)
            if m:
                candidate = m.group("name")
                break
    if not candidate:
        return None

    candidate = re.sub(r"\s+", " ", str(candidate).strip())
    candidate = candidate.strip(" \t\r\n?!.,\"'`")
    candidate = re.sub(r"^(the|a|an)\s+", "", candidate, flags=re.IGNORECASE)
    candidate = re.sub(r"\s*(?:ì´ë¼ëŠ”|ë¼ëŠ”)\s*(?:ì‚¬ëŒ|ì¸ë¬¼)?$", "", candidate, flags=re.IGNORECASE)
    candidate = re.sub(r"\s*(?:please|pls)$", "", candidate, flags=re.IGNORECASE)
    candidate = re.sub(r"(?:ì€|ëŠ”|ì´|ê°€|ì„|ë¥¼|ì™€|ê³¼|ì˜)$", "", candidate)
    candidate = re.sub(r"\s+", " ", candidate).strip()
    if len(candidate) < 2:
        return None
    if len(candidate.split()) > 10:
        return None

    lowered = candidate.lower()
    reject_fragments = {
        "ucsi",
        "university",
        "hostel",
        "tuition",
        "fee",
        "fees",
        "block",
        "building",
        "campus",
        "faculty",
        "department",
        "program",
        "programme",
        "schedule",
        "gpa",
        "cgpa",
        "student id",
        "ê¸°ìˆ™ì‚¬",
        "ë“±ë¡ê¸ˆ",
        "ì „ê³µ",
        "í•™ê³¼",
        "í•™ë¶€",
        "í”„ë¡œê·¸ë¨",
        "ì‹œì„¤",
        "ë„ì„œê´€",
        "ì¼ì •",
        "ì…í•™",
        "ì¥í•™ê¸ˆ",
        "ìº í¼ìŠ¤",
        "êµê³¼",
        "í•™ì ",
        "ì„±ì ",
    }
    if any(fragment in lowered for fragment in reject_fragments):
        return None

    return candidate


def _infer_preferred_labels(message: str, search_term: Optional[str]) -> List[str]:
    q = f"{message or ''} {search_term or ''}".lower()
    labels: List[str] = []

    def add_if_missing(label: str):
        if label not in labels:
            labels.append(label)

    if any(k in q for k in ["hostel", "dorm", "accommodation", "rent", "deposit", "room", "ê¸°ìˆ™ì‚¬", "ìˆ™ì†Œ", "ë£¸", "ë³´ì¦ê¸ˆ"]):
        add_if_missing("Hostel")
    if any(k in q for k in ["hostel faq", "refund", "installment", "policy"]):
        add_if_missing("HostelFAQ")
    if any(k in q for k in ["ê¸°ìˆ™ì‚¬ í™˜ë¶ˆ", "ë¶„í•  ë‚©ë¶€", "ê¸°ìˆ™ì‚¬ ì •ì±…"]):
        add_if_missing("HostelFAQ")
    if any(k in q for k in ["library", "gym", "cafeteria", "facility", "printer", "laundry", "prayer"]):
        add_if_missing("Facility")
    if any(k in q for k in ["ë„ì„œê´€", "ë²„ìŠ¤", "ì²´ìœ¡ê´€", "ì‹œì„¤", "í”„ë¦°í„°", "ì„¸íƒ", "ê¸°ë„ì‹¤"]):
        add_if_missing("Facility")
    if any(k in q for k in ["schedule", "calendar", "event", "semester", "intake", "deadline"]):
        add_if_missing("Schedule")
    if any(k in q for k in ["í•™ì‚¬ì¼ì •", "ì¼ì •", "í•™ê¸°", "ì…í•™ì‹œê¸°", "ë§ˆê°"]):
        add_if_missing("Schedule")
    if any(
        k in q
        for k in [
            "programme",
            "program",
            "major",
            "course",
            "tuition",
            "fee",
            "scholarship",
            "faculty",
            "diploma",
            "foundation",
            "bachelor",
            "master",
            "phd",
            "medicine",
            "health sciences",
            "nursing",
            "pharmacy",
            "engineering",
            "business",
            "computer science",
        ]
    ):
        add_if_missing("Programme")
    if any(k in q for k in ["ì „ê³µ", "í•™ê³¼", "í•™ë¶€", "í”„ë¡œê·¸ë¨", "ë“±ë¡ê¸ˆ", "ì…í•™", "ì˜í•™", "ë³´ê±´", "ê°„í˜¸", "ì•½í•™", "ê³µí•™", "ê²½ì˜"]):
        add_if_missing("Programme")
    if any(k in q for k in ["staff", "lecturer", "professor", "dean", "chancellor", "advisor"]):
        add_if_missing("Staff")
    if any(k in q for k in ["êµìˆ˜", "ê°•ì‚¬", "í•™ì¥", "ì´ì¥", "ë¶€ì´ì¥", "ì§ì›", "ì§€ë„êµìˆ˜"]):
        add_if_missing("Staff")
    if any(k in q for k in ["block", "building", "campus address", "where is block", "map"]):
        add_if_missing("CampusBlocks")
    if any(k in q for k in ["ë¸”ë¡", "ê±´ë¬¼", "ìº í¼ìŠ¤ ìœ„ì¹˜", "ì§€ë„", "ì–´ë””"]):
        add_if_missing("CampusBlocks")

    return labels


def _looks_like_ucsi_domain_info_query(message: str) -> bool:
    q = str(message or "").strip().lower()
    if not q:
        return False

    info_patterns = [
        r"\btell me about\b",
        r"\binformation about\b",
        r"\bdetails about\b",
        r"ì— ëŒ€í•œ ì •ë³´",
        r"ì •ë³´ë¥¼ ì•Œë ¤ì¤˜",
        r"ì„¤ëª…í•´ì¤˜",
    ]
    has_info_request = any(re.search(p, q) for p in info_patterns)

    domain_tokens = [
        "medicine",
        "health sciences",
        "nursing",
        "pharmacy",
        "engineering",
        "business",
        "computer science",
        "faculty",
        "foundation",
        "diploma",
        "bachelor",
        "master",
        "phd",
        "ì˜í•™",
        "ë³´ê±´",
        "ê°„í˜¸",
        "ì•½í•™",
        "ê³µí•™",
        "ê²½ì˜",
        "í•™ë¶€",
        "í•™ê³¼",
        "ì „ê³µ",
    ]
    has_domain_hint = any(token in q for token in domain_tokens)
    return has_info_request and has_domain_hint


def _extract_rag_meta(rag_result: Optional[Dict[str, Any]]) -> Dict[str, Any]:
    result = rag_result or {}
    confidence = 0.0
    try:
        confidence = float(result.get("confidence") or 0.0)
    except Exception:
        confidence = 0.0
    sources = result.get("sources")
    if not isinstance(sources, list):
        sources = []

    return {
        "context": str(result.get("context") or ""),
        "has_relevant_data": bool(result.get("has_relevant_data")),
        "confidence": max(0.0, min(confidence, 1.2)),
        "sources": [str(s) for s in sources[:8]],
    }


def _should_force_rag(message: str) -> bool:
    q = (message or "").strip().lower()
    if not q:
        return False
    if _is_personal_query(q, None):
        return True
    if _infer_preferred_labels(q, None):
        return True
    if _looks_like_ucsi_domain_info_query(q):
        return True
    return any(_contains_token(q, kw) for kw in Config.RAG_FORCE_KEYWORDS)


def _compose_no_data_response(lang: str = "en") -> str:
    if lang == "ko":
        return (
            "í˜„ì¬ UCSI ì§€ì‹ë² ì´ìŠ¤ì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì§€ ëª»í–ˆì–´ìš”. "
            "í”„ë¡œê·¸ë¨ëª…, ë¸”ë¡ëª…, ì…í•™ ì‹œê¸° ë“± êµ¬ì²´ì ì¸ í‚¤ì›Œë“œë¡œ ë‹¤ì‹œ ì§ˆë¬¸í•´ ì£¼ì„¸ìš”."
        )
    return (
        "I could not find reliable information in the current UCSI knowledge base. "
        "Please ask with specific keywords (programme name, block, intake, staff role)."
    )


def _is_document_limited_answer(text: str) -> bool:
    value = str(text or "").lower()
    if not value:
        return False
    patterns = [
        "provided document",
        "provided documents",
        "knowledge base",
        "cannot find",
        "could not find",
        "in our database",
        "ì œê³µëœ ë¬¸ì„œ",
        "ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤",
        "ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ",
    ]
    return any(token in value for token in patterns)


def _detect_language(text: str) -> str:
    content = str(text or "").strip()
    if not content:
        return "en"

    korean_count = 0
    chinese_count = 0
    english_count = 0
    for ch in content:
        code = ord(ch)
        if (0xAC00 <= code <= 0xD7A3) or (0x1100 <= code <= 0x11FF):
            korean_count += 1
        elif (0x4E00 <= code <= 0x9FFF) or (0x3400 <= code <= 0x4DBF):
            chinese_count += 1
        elif ch.isalpha() and code < 128:
            english_count += 1

    if korean_count > chinese_count and korean_count > english_count * 0.3:
        return "ko"
    if chinese_count > korean_count and chinese_count > english_count * 0.3:
        return "zh"
    return "en"


def _is_capability_smalltalk_query(message: str) -> bool:
    q = str(message or "").strip().lower()
    q_compact = re.sub(r"\s+", "", q)
    if not q:
        return False
    if _is_personal_query(q, None) or _has_ucsi_context(q):
        return False

    english_pattern = (
        r"\b(can|could|do|will|would)\s+you\s+"
        r"(please\s+)?(?:(do|perform|try)\s+)?(a\s+)?"
        r"(dance|sing|jump|run|swim|stand|crawl|roll|fly|handstand)\b"
    )
    if re.search(english_pattern, q):
        return True
    if "handstand" in q:
        return True
    if "ë¬¼êµ¬ë‚˜ë¬´" in q_compact:
        return True

    ko_physical_stems = [
        "ë¬¼êµ¬ë‚˜ë¬´",
        "ì¶¤",
        "ë…¸ë˜",
        "ì í”„",
        "ë‹¬ë ¤",
        "ìˆ˜ì˜",
        "ê¸°ì–´",
        "êµ¬ë¥´",
    ]
    ko_request_tokens = ["í•´", "í•´ì¤˜", "í•´ë´", "í•´ì¤„ë˜", "ê°€ëŠ¥í•´", "í• ìˆ˜ìˆì–´", "í•´ë¼", "í•´ë³¼ë˜"]
    return any(stem in q_compact for stem in ko_physical_stems) and any(
        token in q_compact for token in ko_request_tokens
    )


def _capability_smalltalk_response(message: str) -> str:
    q = str(message or "").lower().strip()
    lang = _detect_language(message)
    is_handstand = ("handstand" in q) or ("ë¬¼êµ¬ë‚˜ë¬´" in q)

    # Greeting detection â€” hi, hello, hey, etc.
    greeting_tokens = {
        "hi", "hello", "hey", "hii", "hiii", "yo", "sup",
        "good morning", "good afternoon", "good evening", "good night",
        "ì•ˆë…•", "ì•ˆë…•í•˜ì„¸ìš”", "í•˜ì´", "í—¬ë¡œ", "ë°˜ê°€ì›Œ", "ë°˜ê°‘ìŠµë‹ˆë‹¤",
    }
    q_stripped = re.sub(r"[!?.~,]+$", "", q).strip()
    is_greeting = q_stripped in greeting_tokens or any(q_stripped.startswith(g) for g in greeting_tokens if len(g) > 2)

    if is_greeting:
        if lang == "ko":
            return (
                "ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” UCSI Buddyì˜ˆìš” ğŸ‘‹\n\n"
                "UCSI ëŒ€í•™êµì— ëŒ€í•´ ê¶ê¸ˆí•œ ê±´ ë­ë“  ë¬¼ì–´ë³´ì„¸ìš”!\n"
                "í”„ë¡œê·¸ë¨, ê¸°ìˆ™ì‚¬, ì‹œì„¤, í•™ì‚¬ ì¼ì •, êµì§ì› ì •ë³´ ë“±ì„ ë„ì™€ë“œë¦´ ìˆ˜ ìˆì–´ìš”."
            )
        return (
            "Hello! I'm UCSI Buddy ğŸ‘‹\n\n"
            "Feel free to ask me anything about UCSI University!\n"
            "I can help with programmes, hostel, facilities, schedules, staff info, and more."
        )

    # "What can you do" / "ë­˜ í•´ì¤„ ìˆ˜ ìˆì–´" type questions
    is_what_can = any(kw in q for kw in [
        "what can you", "what do you do", "how can you help",
        "what are you", "who are you", "help me",
        "ë­˜ í•´", "ë­ í•´", "ë¬´ì—‡ì„ í•´", "ë„ì™€", "ë„ì›€",
        "í•  ìˆ˜ ìˆ", "í•´ì¤„ ìˆ˜", "ë­ì•¼", "ëˆ„êµ¬ì•¼", "ëˆ„êµ¬ë‹ˆ",
    ])

    if is_what_can:
        if lang == "ko":
            return (
                "ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” UCSI Buddyì˜ˆìš”. ì´ëŸ° ê²ƒë“¤ì„ ë„ì™€ë“œë¦´ ìˆ˜ ìˆì–´ìš”:\n\n"
                "- UCSI í”„ë¡œê·¸ë¨, ë“±ë¡ê¸ˆ, ì…í•™ ì •ë³´ ì•ˆë‚´\n"
                "- ê¸°ìˆ™ì‚¬ ë¹„ìš©, ì‹œì„¤ ì •ë³´\n"
                "- ìº í¼ìŠ¤ ê±´ë¬¼ ìœ„ì¹˜, ì§€ë„\n"
                "- êµìˆ˜/ì§ì› ì •ë³´\n"
                "- í•™ì‚¬ ì¼ì •, ì‹œí—˜ ì¼ì •\n"
                "- ë¡œê·¸ì¸ í›„ ë‚´ ì„±ì , í”„ë¡œí•„ ì¡°íšŒ\n\n"
                "ê¶ê¸ˆí•œ ê²Œ ìˆìœ¼ë©´ í¸í•˜ê²Œ ë¬¼ì–´ë³´ì„¸ìš”!"
            )
        return (
            "Hi! I'm UCSI Buddy. I can help you with:\n\n"
            "- UCSI programmes, tuition fees, and admissions\n"
            "- Hostel fees and facilities\n"
            "- Campus building locations and maps\n"
            "- Staff and lecturer information\n"
            "- Academic schedules and exam dates\n"
            "- Your grades and profile (after login)\n\n"
            "Feel free to ask me anything!"
        )

    if lang == "ko":
        if is_handstand:
            return "ì €ëŠ” ë¬¼ë¦¬ì ì¸ ëª¸ì´ ì—†ì–´ì„œ ë¬¼êµ¬ë‚˜ë¬´ë¥¼ ì„¤ ìˆ˜ëŠ” ì—†ì–´ìš”. ëŒ€ì‹  ì§ˆë¬¸ì—ëŠ” ì •í™•í•˜ê³  ë¹ ë¥´ê²Œ ë‹µí•  ìˆ˜ ìˆì–´ìš”."
        return "ì €ëŠ” ì‹¤ì œ ë™ì‘ì„ ìˆ˜í–‰í•  ìˆ˜ëŠ” ì—†ì§€ë§Œ, í•„ìš”í•œ ì •ë³´ë¥¼ ì •í™•í•˜ê²Œ ì •ë¦¬í•´ ë“œë¦´ ìˆ˜ ìˆì–´ìš”."

    if is_handstand:
        return "I do not have a physical body, so I cannot do a handstand. But I can answer your questions clearly."
    return "I cannot perform physical actions, but I can provide clear and accurate answers."


def _safe_text_value(value: Any) -> str:
    if value is None:
        return ""
    if isinstance(value, str):
        return re.sub(r"\s+", " ", value).strip()
    if isinstance(value, (dict, list)):
        try:
            return json.dumps(value, ensure_ascii=False)
        except Exception:
            return str(value)
    return str(value).strip()


def _pick_first_value(record: Dict[str, Any], keys: List[str]) -> str:
    for key in keys:
        if key in record:
            value = _safe_text_value(record.get(key))
            if value:
                return value
    return ""


def _requested_personal_fields(message: str, search_term: Optional[str]) -> Optional[set]:
    q = f"{message or ''} {search_term or ''}".lower()
    selected = set()

    if any(k in q for k in ["student number", "student id", "my id", "í•™ë²ˆ", "í•™ìƒë²ˆí˜¸"]):
        selected.add("student_number")
    if any(k in q for k in ["my name", "who am i", "ì´ë¦„", "ë‚´ ì´ë¦„"]):
        selected.add("student_name")
    if any(k in q for k in ["nationality", "where am i from", "êµ­ì "]):
        selected.add("nationality")
    if any(k in q for k in ["gender", "ì„±ë³„"]):
        selected.add("gender")
    if any(k in q for k in ["programme", "program", "major", "ì „ê³µ", "í•™ê³¼"]):
        selected.add("programme")
    if any(k in q for k in ["status", "profile status", "ìƒíƒœ"]):
        selected.add("profile_status")
    if any(k in q for k in ["intake", "ì…í•™"]):
        selected.add("intake")
    if any(k in q for k in ["birth", "birthday", "dob", "ìƒë…„ì›”ì¼", "ìƒì¼"]):
        selected.add("dob")
    if any(k in q for k in ["department", "faculty", "í•™ë¶€", "í•™ê³¼"]):
        selected.add("department")
    if any(k in q for k in ["gpa", "cgpa", "grade", "ì„±ì ", "í•™ì ", "í‰ì "]):
        selected.add("gpa")
    if any(k in q for k in ["advisor", "adviser", "ì§€ë„êµìˆ˜"]):
        selected.add("advisor")

    return selected or None


def _format_personal_info(
    student_data: Dict[str, Any],
    message: str,
    search_term: Optional[str],
    allow_sensitive: bool = True,
) -> str:
    lang = _detect_language(message)
    requested = _requested_personal_fields(message, search_term)
    sensitive_hidden = False

    fields: List[Dict[str, Any]] = [
        {
            "id": "student_number",
            "label_en": "Student Number",
            "label_ko": "í•™ë²ˆ",
            "keys": ["STUDENT_NUMBER", "student_number"],
        },
        {
            "id": "student_name",
            "label_en": "Student Name",
            "label_ko": "ì´ë¦„",
            "keys": ["STUDENT_NAME", "NAME", "name"],
        },
        {
            "id": "nationality",
            "label_en": "Nationality",
            "label_ko": "êµ­ì ",
            "keys": ["NATIONALITY", "nationality"],
        },
        {
            "id": "gender",
            "label_en": "Gender",
            "label_ko": "ì„±ë³„",
            "keys": ["GENDER", "gender"],
        },
        {
            "id": "programme",
            "label_en": "Programme",
            "label_ko": "ì „ê³µ/í”„ë¡œê·¸ë¨",
            "keys": [
                "PROGRAMME_NAME",
                "PROGRAMME",
                "PROGRAM_NAME",
                "MAJOR",
                "programme",
                "program",
                "major",
            ],
        },
        {
            "id": "profile_status",
            "label_en": "Profile Status",
            "label_ko": "ìƒíƒœ",
            "keys": ["PROFILE_STATUS", "STATUS", "profile_status", "status"],
        },
        {
            "id": "intake",
            "label_en": "Intake",
            "label_ko": "ì…í•™ ì‹œê¸°",
            "keys": ["INTAKE", "ADMISSION_INTAKE", "intake"],
        },
        {
            "id": "dob",
            "label_en": "Date of Birth",
            "label_ko": "ìƒë…„ì›”ì¼",
            "keys": ["DATE_OF_BIRTH", "DOB", "BIRTH_DATE", "dob"],
        },
        {
            "id": "department",
            "label_en": "Department",
            "label_ko": "í•™ê³¼",
            "keys": ["DEPARTMENT", "DEPARTMENT_NAME", "FACULTY", "department", "faculty"],
        },
        {
            "id": "gpa",
            "label_en": "GPA",
            "label_ko": "GPA",
            "keys": ["GPA", "CGPA", "gpa", "cgpa"],
        },
        {
            "id": "advisor",
            "label_en": "Advisor",
            "label_ko": "ì§€ë„êµìˆ˜",
            "keys": ["ADVISOR", "ADVISER", "advisor", "adviser"],
        },
    ]

    lines: List[str] = []
    for field in fields:
        if field["id"] == "gpa" and not allow_sensitive:
            if requested is None or field["id"] in requested:
                sensitive_hidden = True
            continue
        if requested and field["id"] not in requested:
            continue
        value = _pick_first_value(student_data, field["keys"])
        if not value:
            if requested and field["id"] in requested:
                label = field["label_ko"] if lang == "ko" else field["label_en"]
                missing = "ì •ë³´ ì—†ìŒ" if lang == "ko" else "Not available"
                lines.append(f"{label}: {missing}")
            continue
        label = field["label_ko"] if lang == "ko" else field["label_en"]
        lines.append(f"{label}: {value}")

    if not lines:
        if sensitive_hidden:
            if lang == "ko":
                return "GPA/ì„±ì  ì •ë³´ëŠ” ë¹„ë°€ë²ˆí˜¸ ì¸ì¦ í›„ì— í™•ì¸í•  ìˆ˜ ìˆì–´ìš”."
            return "GPA/grade information is available after password verification."
        if lang == "ko":
            return "ìš”ì²­í•˜ì‹  í•™ìƒ ì •ë³´ë¥¼ ì°¾ì§€ ëª»í–ˆì–´ìš”."
        return "I could not find your student profile details."

    header = "ìš”ì²­í•˜ì‹  í•™ìƒ ì •ë³´ì…ë‹ˆë‹¤." if lang == "ko" else "Here is your profile information."
    text = header + "\n\n" + "\n".join(lines)
    if sensitive_hidden:
        if lang == "ko":
            text += "\n\nGPA/ì„±ì  ì •ë³´ëŠ” ë¹„ë°€ë²ˆí˜¸ ì¸ì¦ í›„ì— ì œê³µë©ë‹ˆë‹¤."
        else:
            text += "\n\nGPA/grade details are shown after password verification."
    return text


def _personal_info_suggestions(lang: str, allow_sensitive: bool = True) -> List[str]:
    if lang == "ko":
        if allow_sensitive:
            return ["ë‚´ GPAë§Œ ë³´ì—¬ì¤˜", "ë‚´ êµ­ì  ì•Œë ¤ì¤˜", "ë‚´ ì§€ë„êµìˆ˜ê°€ ëˆ„êµ¬ì•¼?"]
        return ["ë‚´ êµ­ì  ì•Œë ¤ì¤˜", "ë‚´ ì „ê³µ ì•Œë ¤ì¤˜", "ë‚´ ì§€ë„êµìˆ˜ê°€ ëˆ„êµ¬ì•¼?"]
    if allow_sensitive:
        return ["Show only my GPA", "What is my nationality?", "Who is my advisor?"]
    return ["What is my nationality?", "What is my programme?", "Who is my advisor?"]


def _capability_suggestions(lang: str) -> List[str]:
    if lang == "ko":
        return ["ë‚´ ì •ë³´ ë³´ì—¬ì¤˜", "UCSI ê¸°ìˆ™ì‚¬ ì •ë³´ ì•Œë ¤ì¤˜", "UCSI ë“±ë¡ê¸ˆ ì •ë³´ ì•Œë ¤ì¤˜"]
    return ["Show my profile", "Tell me about UCSI hostel", "Tell me about UCSI tuition fees"]


def _extract_suggestion_tokens(text: str) -> List[str]:
    source = str(text or "").lower()
    if not source:
        return []

    raw_tokens = re.findall(r"[a-z0-9]{2,}|[ê°€-í£]{2,}", source)
    en_stop = {
        "what",
        "where",
        "who",
        "when",
        "how",
        "why",
        "is",
        "are",
        "the",
        "a",
        "an",
        "to",
        "for",
        "of",
        "in",
        "on",
        "about",
        "please",
        "tell",
        "show",
        "me",
        "my",
        "can",
        "you",
    }
    ko_stop = {
        "ì•Œë ¤ì¤˜",
        "ì•Œë ¤",
        "ë§í•´ì¤˜",
        "ë§í•´",
        "ë­ì•¼",
        "ë¬´ì—‡",
        "ì–´ë””",
        "ì–´ë–»ê²Œ",
        "ëˆ„êµ¬",
        "ì™œ",
        "ì¢€",
        "í•´ì¤˜",
        "í•´",
        "ìˆì–´",
    }

    out: List[str] = []
    for tok in raw_tokens:
        if re.search(r"[a-z]", tok):
            if tok in en_stop:
                continue
        elif tok in ko_stop:
            continue
        out.append(tok)
    return out


def _infer_suggestion_bucket(
    *,
    user_message: str,
    search_term: Optional[str],
    retrieval_meta: Dict[str, Any],
    is_personal: bool,
    person_resolution: Optional[Dict[str, Any]],
) -> str:
    q = f"{user_message or ''} {search_term or ''}".lower()
    route = str((retrieval_meta or {}).get("route") or "")
    labels = retrieval_meta.get("preferred_labels") if isinstance(retrieval_meta, dict) else []
    labels = {str(x) for x in labels} if isinstance(labels, list) else set()
    match_type = str((person_resolution or {}).get("match_type") or "")

    if route == "capability_smalltalk":
        return "capability"
    if is_personal:
        if _is_grade_query(user_message, search_term):
            return "personal_grade"
        return "personal_profile"
    if match_type == "general_person":
        return "general_person"
    if match_type == "db_staff_match" or "Staff" in labels:
        return "staff"
    if "Hostel" in labels or any(k in q for k in ["hostel", "dorm", "accommodation", "ê¸°ìˆ™ì‚¬"]):
        return "hostel"
    if "Facility" in labels or any(k in q for k in ["library", "gym", "printer", "facility", "ì‹œì„¤"]):
        return "facility"
    if "Schedule" in labels or any(k in q for k in ["schedule", "calendar", "semester", "intake", "ì¼ì •"]):
        return "schedule"
    if "Programme" in labels or any(
        k in q for k in ["programme", "program", "major", "course", "tuition", "fee", "ì „ê³µ", "í•™ê³¼", "ë“±ë¡ê¸ˆ"]
    ):
        return "programme"
    if "CampusBlocks" in labels or any(k in q for k in ["block", "building", "map", "ìº í¼ìŠ¤", "ê±´ë¬¼"]):
        return "campus_blocks"

    confidence = 0.0
    try:
        confidence = float((retrieval_meta or {}).get("confidence") or 0.0)
    except Exception:
        confidence = 0.0
    if route in {"rag", "planner_rag"} and confidence < 0.45:
        return "rag_no_data"
    if not _has_ucsi_context(user_message):
        return "general_world"
    return "general_ucsi"


def _bucket_templates(
    *,
    bucket: str,
    lang: str,
    person_resolution: Optional[Dict[str, Any]],
) -> List[str]:
    candidate = str((person_resolution or {}).get("candidate") or "").strip()

    if lang == "ko":
        templates = {
            "capability": ["ë‚´ ì •ë³´ ë³´ì—¬ì¤˜", "UCSI í”„ë¡œê·¸ë¨ ì¶”ì²œí•´ì¤˜", "UCSI ê¸°ìˆ™ì‚¬ ì •ë³´ ì•Œë ¤ì¤˜"],
            "personal_profile": ["ë‚´ êµ­ì  ì•Œë ¤ì¤˜", "ë‚´ ì „ê³µ ì•Œë ¤ì¤˜", "ë‚´ ì§€ë„êµìˆ˜ê°€ ëˆ„êµ¬ì•¼?"],
            "personal_grade": ["ë‚´ GPAì™€ CGPA ë³´ì—¬ì¤˜", "ìµœê·¼ ì„±ì  ì•Œë ¤ì¤˜", "ë‚´ í•™ë²ˆë„ í•¨ê»˜ ë³´ì—¬ì¤˜"],
            "hostel": ["ê¸°ìˆ™ì‚¬ ë¹„ìš© ì•Œë ¤ì¤˜", "ê¸°ìˆ™ì‚¬ ë³´ì¦ê¸ˆì€ ì–¼ë§ˆì•¼?", "ê¸°ìˆ™ì‚¬ ë¶„í• ë‚©ë¶€ ê°€ëŠ¥í•´?"],
            "facility": ["ë„ì„œê´€ ìœ„ì¹˜ ì•Œë ¤ì¤˜", "ìº í¼ìŠ¤ì— ì²´ìœ¡ê´€ ìˆì–´?", "í”„ë¦°í„°ëŠ” ì–´ë””ì— ìˆì–´?"],
            "schedule": ["ë‹¤ìŒ í•™ê¸° ì‹œì‘ì¼ ì•Œë ¤ì¤˜", "ì£¼ìš” í•™ì‚¬ ì¼ì • ì•Œë ¤ì¤˜", "ì‹œí—˜ ê¸°ê°„ì€ ì–¸ì œì•¼?"],
            "programme": ["ì´ ì „ê³µ ë“±ë¡ê¸ˆ ì•Œë ¤ì¤˜", "ì…í•™ ì¡°ê±´ ì•Œë ¤ì¤˜", "ì–´ëŠ í•™ë¶€ì—ì„œ ìš´ì˜í•´?"],
            "staff": ["ì´ êµìˆ˜ì˜ ì—­í• ì´ ë­ì•¼?", "ì´ ì‚¬ëŒ ì—°ë½ì²˜ ì•Œë ¤ì¤˜", "í•´ë‹¹ í•™ë¶€ í•™ì¥ì€ ëˆ„êµ¬ì•¼?"],
            "campus_blocks": ["Block AëŠ” ì–´ë””ì•¼?", "Block BëŠ” ì–´ë–»ê²Œ ê°€?", "ë©”ì¸ ì˜¤í”¼ìŠ¤ëŠ” ì–´ëŠ ë¸”ë¡ì´ì•¼?"],
            "general_person": ["ëŒ€í‘œì‘ì´ ë­ì•¼?", "ìµœê·¼ í™œë™ì´ ë­ì•¼?", "ì–¸ì œ ë°ë·”í–ˆì–´?"],
            "rag_no_data": ["ì •í™•í•œ ì „ê³µëª…ìœ¼ë¡œ ë‹¤ì‹œ ë¬¼ì–´ë³¼ê²Œ", "ê±´ë¬¼ëª…/ë¸”ë¡ëª…ì„ ë„£ì–´ì„œ ë¬¼ì–´ë³¼ê²Œ", "ì§ì±…ê³¼ í•™ë¶€ë¥¼ ê°™ì´ ë„£ì–´ ë¬¼ì–´ë³¼ê²Œ"],
            "general_world": ["ë¨¸ì‹ ëŸ¬ë‹ ì‰½ê²Œ ì„¤ëª…í•´ì¤˜", "ë§ë ˆì´ì‹œì•„ ìˆ˜ë„ê°€ ì–´ë””ì•¼?", "íŒŒì´ì¬ì´ ë­ì•¼?"],
            "general_ucsi": ["UCSI í”„ë¡œê·¸ë¨ ì •ë³´ ì•Œë ¤ì¤˜", "ìº í¼ìŠ¤ ì‹œì„¤ ì•Œë ¤ì¤˜", "ë“±ë¡ê¸ˆ êµ¬ì¡° ì„¤ëª…í•´ì¤˜"],
        }
    else:
        templates = {
            "capability": ["Show my profile", "Recommend a UCSI programme", "Tell me about UCSI hostel"],
            "personal_profile": ["What is my nationality?", "What is my programme?", "Who is my advisor?"],
            "personal_grade": ["Show my GPA and CGPA", "What is my latest result?", "Show my student number too"],
            "hostel": ["What are the hostel fees?", "How much is the hostel deposit?", "Can I pay hostel by installment?"],
            "facility": ["Where is the library?", "Is there a gym on campus?", "Where can I print documents?"],
            "schedule": ["When does the next semester start?", "What are the intake dates?", "When is the exam period?"],
            "programme": ["What is the tuition fee for this programme?", "What are the entry requirements?", "Which faculty offers it?"],
            "staff": ["What is this staff member's role?", "How can I contact this person?", "Who is the dean of this faculty?"],
            "campus_blocks": ["Where is Block A?", "How do I get to Block B?", "Which block has the main office?"],
            "general_person": ["What is this person's most well-known work?", "What are this person's recent activities?", "When did this person debut?"],
            "rag_no_data": ["Include the exact programme name", "Ask with block/building name", "Include staff role and faculty"],
            "general_world": ["Explain machine learning simply", "What is the capital of Malaysia?", "What is Python used for?"],
            "general_ucsi": ["Tell me about UCSI programmes", "Show campus facilities", "Explain tuition fee structure"],
        }

    picked = list(templates.get(bucket, templates.get("general_ucsi", [])))
    if bucket == "general_person" and candidate:
        if lang == "ko":
            picked.insert(0, f"{candidate}ì˜ ëŒ€í‘œì‘ì€ ë­ì•¼?")
            picked.insert(1, f"{candidate}ì˜ ìµœê·¼ í™œë™ ì•Œë ¤ì¤˜")
        else:
            picked.insert(0, f"What is {candidate}'s most well-known work?")
            picked.insert(1, f"What has {candidate} been doing recently?")
    return picked


def _generic_suggestion_fallback(lang: str) -> List[str]:
    if lang == "ko":
        return ["UCSI ê¸°ìˆ™ì‚¬ ì •ë³´ ì•Œë ¤ì¤˜", "UCSI ë“±ë¡ê¸ˆ ì•Œë ¤ì¤˜", "ë§ë ˆì´ì‹œì•„ ìœ í•™ ê´€ë ¨ ì •ë³´ ì•Œë ¤ì¤˜"]
    return ["Tell me about UCSI hostel", "What are the tuition fees?", "Any tips for studying in Malaysia?"]


def _suggestion_score(
    *,
    suggestion: str,
    user_tokens: set,
    lang: str,
    bucket: str,
    candidate_index: int,
) -> float:
    text = str(suggestion or "").strip()
    if not text:
        return -999.0

    tokens = set(_extract_suggestion_tokens(text))
    overlap = len(tokens.intersection(user_tokens))
    score = float(overlap * 4)

    # Keep earlier candidates slightly preferred when scores tie.
    score += max(0.0, 2.0 - (candidate_index * 0.12))

    if len(text) < 6 or len(text) > 95:
        score -= 1.2

    sl = _detect_language(text)
    if lang == "ko" and sl != "ko":
        score -= 1.2
    if lang != "ko" and sl == "ko":
        score -= 1.2

    if bucket in {"personal_profile", "personal_grade"} and (
        ("my " in text.lower()) or ("ë‚´ " in text) or text.startswith("ë‚´")
    ):
        score += 1.0
    return score


def _is_redundant_person_suggestion(
    suggestion: str,
    user_message: str,
    candidate: str,
) -> bool:
    s = str(suggestion or "").strip().lower()
    u = str(user_message or "").strip().lower()
    c = str(candidate or "").strip().lower()
    if not s:
        return True
    if s == u:
        return True
    if not c:
        return False

    repetitive_patterns = [
        rf"^who is\s+{re.escape(c)}\??$",
        rf"^who's\s+{re.escape(c)}\??$",
        rf"^tell me about\s+{re.escape(c)}\??$",
        rf"^tell me more about\s+{re.escape(c)}\??$",
        rf"^{re.escape(c)}\s*(?:ëˆ„êµ¬ì•¼|ëˆ„êµ¬ì˜ˆìš”|ëˆ„êµ°ê°€ìš”)\??$",
        rf"^{re.escape(c)}\s*(?:ì— ëŒ€í•´|ì—ëŒ€í•´|ì— ëŒ€í•´ì„œ|ì—ëŒ€í•´ì„œ|ê´€ë ¨í•´ì„œ|ì— ê´€í•œ)\s*(?:ì •ë³´ë¥¼\s*)?(?:ì•Œë ¤ì¤˜|ì•Œë ¤ì¤„ë˜|ì•Œë ¤ì£¼ì„¸ìš”|ë§í•´ì¤˜|ë§í•´ì¤„ë˜|ì„¤ëª…í•´ì¤˜|ì†Œê°œí•´ì¤˜)?\??$",
    ]
    return any(re.match(p, s, flags=re.IGNORECASE) for p in repetitive_patterns)


def _build_suggestions(
    *,
    user_message: str,
    user_lang: str,
    retrieval_meta: Dict[str, Any],
    ai_suggestions: Any,
    is_personal: bool,
    search_term: Optional[str],
    person_resolution: Optional[Dict[str, Any]],
    limit: int = 3,
) -> List[str]:
    bucket = _infer_suggestion_bucket(
        user_message=user_message,
        search_term=search_term,
        retrieval_meta=retrieval_meta,
        is_personal=is_personal,
        person_resolution=person_resolution,
    )
    candidate = str((person_resolution or {}).get("candidate") or "").strip()

    candidates: List[str] = []
    candidates.extend(_normalize_suggestions(ai_suggestions, limit=8))
    candidates.extend(
        _bucket_templates(bucket=bucket, lang=user_lang, person_resolution=person_resolution)
    )
    candidates.extend(_generic_suggestion_fallback(user_lang))

    user_key = re.sub(r"\s+", " ", str(user_message or "").lower()).strip(" ?!.,")
    user_tokens = set(_extract_suggestion_tokens(user_message))

    ranked: List[tuple] = []
    seen = set()
    for idx, raw in enumerate(candidates):
        text = re.sub(r"\s+", " ", str(raw or "").strip())
        if not text:
            continue
        key = text.lower()
        if key in seen:
            continue
        seen.add(key)
        if key == user_key:
            continue
        if bucket == "general_person" and _is_redundant_person_suggestion(
            suggestion=text,
            user_message=user_message,
            candidate=candidate,
        ):
            continue
        score = _suggestion_score(
            suggestion=text,
            user_tokens=user_tokens,
            lang=user_lang,
            bucket=bucket,
            candidate_index=idx,
        )
        ranked.append((score, idx, text))

    ranked.sort(key=lambda x: (-x[0], x[1]))
    out = [text for _, _, text in ranked[: max(1, int(limit))]]
    return out


